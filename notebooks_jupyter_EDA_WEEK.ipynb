{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efb31865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/15 16:18:01 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, MinMaxScaler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import col, unix_timestamp, hour, dayofweek, month, udf, when\n",
    "from pyspark.sql.types import FloatType\n",
    "import math\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"Taxi Fare Prediction\").getOrCreate()\n",
    "\n",
    "\n",
    "data = spark.read.csv('gs://228bucket/processed_train_2.0.csv/processed_dataset_2.0.csv', header=True, inferSchema=True)\n",
    "\n",
    "\n",
    "# Convert datetime and extract features\n",
    "data = data.withColumn(\"pickup_datetime\", unix_timestamp(col(\"pickup_datetime\"), \"yyyy-MM-dd'T'HH:mm:ss.SSSX\").cast(\"timestamp\"))\n",
    "data = data.withColumn(\"pickup_hour\", hour(col(\"pickup_datetime\")))\n",
    "data = data.withColumn(\"day_of_week\", dayofweek(col(\"pickup_datetime\")))\n",
    "data = data.withColumn(\"month\", month(col(\"pickup_datetime\")))\n",
    "\n",
    "# Define the distance calculation function\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    R = 6371.0  # Radius of the Earth in kilometers\n",
    "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = math.sin(dlat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2) ** 2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    return float(R * c)\n",
    "\n",
    "udf_calculate_distance = udf(calculate_distance, FloatType())\n",
    "data = data.withColumn(\"distance\", udf_calculate_distance(col(\"pickup_latitude\"), col(\"pickup_longitude\"), col(\"dropoff_latitude\"), col(\"dropoff_longitude\")))\n",
    "\n",
    "# Create a new column 'is_weekend' where 1 if the day is Saturday (7) or Sunday (1), otherwise 0\n",
    "data = data.withColumn(\"is_weekend\", when(col(\"day_of_week\").isin([7, 1]), 1).otherwise(0))\n",
    "\n",
    "# One-hot encoding for 'day_of_week'\n",
    "day_of_week_indexer = StringIndexer(inputCol=\"day_of_week\", outputCol=\"day_of_week_index\")\n",
    "day_of_week_encoder = OneHotEncoder(inputCols=[\"day_of_week_index\"], outputCols=[\"day_of_week_encoded\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4c8bbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the DataFrame as a SQL temporary view\n",
    "data.createOrReplaceTempView(\"taxi_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49267f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------+-------+\n",
      "|         col_name|data_type|comment|\n",
      "+-----------------+---------+-------+\n",
      "|      fare_amount|   double|   NULL|\n",
      "|  pickup_datetime|timestamp|   NULL|\n",
      "| pickup_longitude|   double|   NULL|\n",
      "|  pickup_latitude|   double|   NULL|\n",
      "|dropoff_longitude|   double|   NULL|\n",
      "| dropoff_latitude|   double|   NULL|\n",
      "|  passenger_count|      int|   NULL|\n",
      "|      pickup_hour|      int|   NULL|\n",
      "|      day_of_week|      int|   NULL|\n",
      "|            month|      int|   NULL|\n",
      "|         distance|    float|   NULL|\n",
      "|       is_weekend|      int|   NULL|\n",
      "+-----------------+---------+-------+\n",
      "\n",
      "+-----------------+---------+-------+\n",
      "|         col_name|data_type|comment|\n",
      "+-----------------+---------+-------+\n",
      "|      fare_amount|   double|   NULL|\n",
      "|  pickup_datetime|timestamp|   NULL|\n",
      "| pickup_longitude|   double|   NULL|\n",
      "|  pickup_latitude|   double|   NULL|\n",
      "|dropoff_longitude|   double|   NULL|\n",
      "| dropoff_latitude|   double|   NULL|\n",
      "|  passenger_count|      int|   NULL|\n",
      "|      pickup_hour|      int|   NULL|\n",
      "|      day_of_week|      int|   NULL|\n",
      "|            month|      int|   NULL|\n",
      "|         distance|    float|   NULL|\n",
      "|       is_weekend|      int|   NULL|\n",
      "+-----------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the schema of the DataFrame\n",
    "spark.sql(\"DESCRIBE taxi_data\").show()\n",
    "\n",
    "# Display summary statistics for all numerical columns\n",
    "spark.sql(\"DESCRIBE TABLE EXTENDED taxi_data\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d630583",
   "metadata": {},
   "source": [
    "## Distribution of Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae2c9bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+------------------+------------------+\n",
      "|min(distance)|max(distance)|     avg(distance)|  stddev(distance)|\n",
      "+-------------+-------------+------------------+------------------+\n",
      "|          0.0|      19688.8|20.420034621872315|375.50659528892106|\n",
      "+-------------+-------------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 56:=====================================================>  (23 + 1) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+------------------+-------------------+\n",
      "|min(fare_amount)|max(fare_amount)|  avg(fare_amount)|stddev(fare_amount)|\n",
      "+----------------+----------------+------------------+-------------------+\n",
      "|             0.0|          1564.5|11.460607645597454|   9.89161559220771|\n",
      "+----------------+----------------+------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Get summary statistics for 'distance' and 'fare_amount'\n",
    "spark.sql(\"SELECT MIN(distance), MAX(distance), AVG(distance), STDDEV(distance) FROM taxi_data\").show()\n",
    "spark.sql(\"SELECT MIN(fare_amount), MAX(fare_amount), AVG(fare_amount), STDDEV(fare_amount) FROM taxi_data\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4f3f11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Weekend vs. Weekday Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "381677b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 59:=====================================================>  (23 + 1) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+------------------+------------------+--------+--------+------------+------------+\n",
      "|is_weekend|total_rides|      average_fare|  average_distance|min_fare|max_fare|min_distance|max_distance|\n",
      "+----------+-----------+------------------+------------------+--------+--------+------------+------------+\n",
      "|         0|   30688693| 11.48504679036261|20.751315419639518|     0.0|  1021.3|         0.0|   14010.494|\n",
      "|         1|   12137800|11.398816760038915| 19.58243845951397|     0.0|  1564.5|         0.0|     19688.8|\n",
      "+----------+-----------+------------------+------------------+--------+--------+------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Statistics for weekends and weekdays\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    is_weekend,\n",
    "    COUNT(*) as total_rides,\n",
    "    AVG(fare_amount) as average_fare,\n",
    "    AVG(distance) as average_distance,\n",
    "    MIN(fare_amount) as min_fare,\n",
    "    MAX(fare_amount) as max_fare,\n",
    "    MIN(distance) as min_distance,\n",
    "    MAX(distance) as max_distance\n",
    "FROM \n",
    "    taxi_data\n",
    "GROUP BY \n",
    "    is_weekend\n",
    "ORDER BY \n",
    "    is_weekend\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb544061",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Detailed Day Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3c65797",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 62:=====================================================>  (23 + 1) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+------------------+------------------+--------+--------+------------+------------+\n",
      "|day_of_week|total_rides|      average_fare|  average_distance|min_fare|max_fare|min_distance|max_distance|\n",
      "+-----------+-----------+------------------+------------------+--------+--------+------------+------------+\n",
      "|          1|    5639700|11.746857809813179|19.803206929371882|     0.0|   500.0|         0.0|   12594.705|\n",
      "|          2|    5517934|11.496004223683046|20.841823721019924|     0.0|   500.0|         0.0|   10833.611|\n",
      "|          3|    5998528| 11.30810133086045|20.671720521808535|     0.0|  1021.3|         0.0|   13642.391|\n",
      "|          4|    6229111|11.430351493175094|20.820634117768762|     0.0|  651.07|         0.0|   14010.494|\n",
      "|          5|    6380151|11.632963298204645|20.935260657605856|     0.0|   900.0|         0.0|   10003.499|\n",
      "|          6|    6562969|11.545678391899033|20.503354646222494|     0.0|   668.5|         0.0|   13912.815|\n",
      "|          7|    6498100|11.096751985965502| 19.39083353815887|     0.0|  1564.5|         0.0|     19688.8|\n",
      "+-----------+-----------+------------------+------------------+--------+--------+------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 64:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Ride statistics by day of the week\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    day_of_week,\n",
    "    COUNT(*) as total_rides,\n",
    "    AVG(fare_amount) as average_fare,\n",
    "    AVG(distance) as average_distance,\n",
    "    MIN(fare_amount) as min_fare,\n",
    "    MAX(fare_amount) as max_fare,\n",
    "    MIN(distance) as min_distance,\n",
    "    MAX(distance) as max_distance\n",
    "FROM \n",
    "    taxi_data\n",
    "GROUP BY \n",
    "    day_of_week\n",
    "ORDER BY \n",
    "    day_of_week\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3dcd642",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monthly Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00e594c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 65:=====================================================>  (23 + 1) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+------------------+------------------+\n",
      "|month|total_rides|      average_fare|  average_distance|\n",
      "+-----+-----------+------------------+------------------+\n",
      "|    1|    3572234|10.712232205393574|16.185484993761705|\n",
      "|    2|    3349804|10.821751397992696|19.558332194151696|\n",
      "|    3|    3789413|11.109660622899193| 19.25480646131086|\n",
      "|    4|    3725183|11.243589198168834|19.585699783740385|\n",
      "|    5|    3820850|11.558851347214029|20.038573508940722|\n",
      "|    6|    3645118|11.533138408688615| 21.33160607122314|\n",
      "|    7|    3505655|11.320181780580763|22.856694370016363|\n",
      "|    8|    3254499| 11.46909976620101|25.027901898194685|\n",
      "|    9|    3504697|12.026139945907673|20.717392173954508|\n",
      "|   10|    3672239|11.962919317071464|19.889687187285663|\n",
      "|   11|    3480154|11.857780172947088|20.245097873822775|\n",
      "|   12|    3506647|11.907693429079835|  20.8898482782378|\n",
      "+-----+-----------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 67:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Monthly ride statistics\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    month,\n",
    "    COUNT(*) as total_rides,\n",
    "    AVG(fare_amount) as average_fare,\n",
    "    AVG(distance) as average_distance\n",
    "FROM \n",
    "    taxi_data\n",
    "GROUP BY \n",
    "    month\n",
    "ORDER BY \n",
    "    month\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8220518",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Average Distance Traveled per Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fb59ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 68:=====================================================>  (23 + 1) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|month|  average_distance|\n",
      "+-----+------------------+\n",
      "|    1|  16.1854849937617|\n",
      "|    2|19.558332194151692|\n",
      "|    3|19.254806461310864|\n",
      "|    4|19.585699783740377|\n",
      "|    5|20.038573508940715|\n",
      "|    6|21.331606071223135|\n",
      "|    7|22.856694370016374|\n",
      "|    8|25.027901898194692|\n",
      "|    9| 20.71739217395451|\n",
      "|   10|19.889687187285663|\n",
      "|   11|20.245097873822772|\n",
      "|   12|  20.8898482782378|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/15 16:33:38 ERROR TransportResponseHandler: Still have 1 requests outstanding when connection from /10.128.0.5:60950 is closed\n",
      "24/05/15 16:33:38 WARN BlockManagerMasterEndpoint: Error trying to remove broadcast 74 from block manager BlockManagerId(18, cluster-789c-w-0.us-central1-f.c.vertical-kayak-423108-t5.internal, 43387, None)\n",
      "java.io.IOException: Connection from /10.128.0.5:60950 closed\n",
      "\tat org.apache.spark.network.client.TransportResponseHandler.channelInactive(TransportResponseHandler.java:147) ~[spark-network-common_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.network.server.TransportChannelHandler.channelInactive(TransportChannelHandler.java:117) ~[spark-network-common_2.12-3.5.0.jar:3.5.0]\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:305) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:281) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:274) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n",
      "\tat io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n",
      "\tat io.netty.handler.timeout.IdleStateHandler.channelInactive(IdleStateHandler.java:277) ~[netty-handler-4.1.100.Final.jar:4.1.100.Final]\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:303) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:281) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:274) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n",
      "\tat io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n",
      "\tat org.apache.spark.network.util.TransportFrameDecoder.channelInactive(TransportFrameDecoder.java:225) ~[spark-network-common_2.12-3.5.0.jar:3.5.0]\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:305) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:281) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:274) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1405) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:301) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:281) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n",
      "\tat io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:901) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe$7.run(AbstractChannel.java:813) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n",
      "\tat io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java:173) ~[netty-common-4.1.100.Final.jar:4.1.100.Final]\n",
      "\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:166) ~[netty-common-4.1.100.Final.jar:4.1.100.Final]\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:470) ~[netty-common-4.1.100.Final.jar:4.1.100.Final]\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:566) ~[netty-transport-4.1.100.Final.jar:4.1.100.Final]\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997) ~[netty-common-4.1.100.Final.jar:4.1.100.Final]\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.100.Final.jar:4.1.100.Final]\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.100.Final.jar:4.1.100.Final]\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829) [?:?]\n"
     ]
    }
   ],
   "source": [
    "# Average distance traveled per month\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    month,\n",
    "    AVG(distance) as average_distance\n",
    "FROM \n",
    "    taxi_data\n",
    "GROUP BY \n",
    "    month\n",
    "ORDER BY \n",
    "    month\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f723b622",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Average Distance Traveled per Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a79d5389",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 71:=====================================================>  (23 + 1) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|week_of_year|  average_distance|\n",
      "+------------+------------------+\n",
      "|           1| 16.69180027085385|\n",
      "|           2| 16.50167219568823|\n",
      "|           3|15.660032904287828|\n",
      "|           4|16.484110867833095|\n",
      "|           5|19.107593688076978|\n",
      "|           6| 19.65414048830177|\n",
      "|           7|19.643598056514982|\n",
      "|           8| 19.96502899361394|\n",
      "|           9|20.124095467551744|\n",
      "|          10|19.188544097616877|\n",
      "|          11| 18.95373901160854|\n",
      "|          12|18.531580179701585|\n",
      "|          13|19.437887565315375|\n",
      "|          14|19.194391544324226|\n",
      "|          15| 19.33432891900656|\n",
      "|          16| 19.64735716401732|\n",
      "|          17|19.403530474292314|\n",
      "|          18|19.173139839411043|\n",
      "|          19| 19.90196610267479|\n",
      "|          20| 20.06397784067553|\n",
      "+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Assuming 'pickup_datetime' can be used to extract week of the year\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    weekofyear(pickup_datetime) as week_of_year,\n",
    "    AVG(distance) as average_distance\n",
    "FROM \n",
    "    taxi_data\n",
    "GROUP BY \n",
    "    week_of_year\n",
    "ORDER BY \n",
    "    week_of_year\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab124b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000f513b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}