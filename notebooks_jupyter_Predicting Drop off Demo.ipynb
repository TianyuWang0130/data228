{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27658161",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/16 01:58:08 INFO SparkEnv: Registering MapOutputTracker\n",
      "24/05/16 01:58:09 INFO SparkEnv: Registering BlockManagerMaster\n",
      "24/05/16 01:58:09 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "24/05/16 01:58:09 INFO SparkEnv: Registering OutputCommitCoordinator\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import RandomForestRegressionModel\n",
    "\n",
    "spark = SparkSession.builder.appName(\"DropOffCoordinatesDemo\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc0e54bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Schema:\n",
      "root\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- pickup_longitude: double (nullable = true)\n",
      " |-- pickup_latitude: double (nullable = true)\n",
      " |-- dropoff_longitude: double (nullable = true)\n",
      " |-- dropoff_latitude: double (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:====================================================>    (22 + 2) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows in Test Data: 4312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data = spark.read.csv('gs://228bucket/processed_train_2.0.csv/processed_dataset_2.0.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Create test data by sampling from the original data\n",
    "test_data = data.sample(withReplacement=False, fraction=0.0001)\n",
    "\n",
    "# Show some information about the test data\n",
    "print(\"Test Data Schema:\")\n",
    "test_data.printSchema()\n",
    "\n",
    "print(\"Number of Rows in Test Data:\", test_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c15b315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "test_data.write.csv('gs://228bucket/test_2demo_data.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6ea13e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+----------------+---------------+-----------------+----------------+---------------+\n",
      "|fare_amount|    pickup_datetime|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|passenger_count|\n",
      "+-----------+-------------------+----------------+---------------+-----------------+----------------+---------------+\n",
      "|       12.9|2011-01-29 01:50:07|             0.0|            0.0|              0.0|             0.0|              1|\n",
      "|       11.7|2011-07-28 00:08:28|      -73.989378|      40.741525|       -73.955272|       40.776918|              1|\n",
      "|       12.1|2010-01-21 04:17:34|      -73.988655|      40.758316|        -74.01221|       40.707129|              1|\n",
      "|        8.5|2013-03-30 08:58:00|       -73.95023|       40.77969|       -73.968578|       40.761727|              1|\n",
      "|        5.0|2014-12-20 19:30:00|      -73.991202|      40.750822|       -73.984685|       40.742962|              1|\n",
      "+-----------+-------------------+----------------+---------------+-----------------+----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data = spark.read.csv('gs://228bucket/test_2demo_data.csv', header=True, inferSchema=True)\n",
    "test_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e928ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+----------------+---------------+-----------------+----------------+---------------+-----------+---------------------+--------------------+\n",
      "|fare_amount|    pickup_datetime|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|passenger_count|pickup_time|seconds_from_midnight|            features|\n",
      "+-----------+-------------------+----------------+---------------+-----------------+----------------+---------------+-----------+---------------------+--------------------+\n",
      "|       12.9|2011-01-29 01:50:07|             0.0|            0.0|              0.0|             0.0|              1|   01:50:07|                 6607|[6607.0,0.0,0.0,1.0]|\n",
      "|       11.7|2011-07-28 00:08:28|      -73.989378|      40.741525|       -73.955272|       40.776918|              1|   00:08:28|                  508|[508.0,-73.989378...|\n",
      "|       12.1|2010-01-21 04:17:34|      -73.988655|      40.758316|        -74.01221|       40.707129|              1|   04:17:34|                15454|[15454.0,-73.9886...|\n",
      "|        8.5|2013-03-30 08:58:00|       -73.95023|       40.77969|       -73.968578|       40.761727|              1|   08:58:00|                32280|[32280.0,-73.9502...|\n",
      "|        5.0|2014-12-20 19:30:00|      -73.991202|      40.750822|       -73.984685|       40.742962|              1|   19:30:00|                70200|[70200.0,-73.9912...|\n",
      "+-----------+-------------------+----------------+---------------+-----------------+----------------+---------------+-----------+---------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 11:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, split\n",
    "from pyspark.sql.functions import from_unixtime, unix_timestamp, col\n",
    "# split the time string into hours, minutes and seconds\n",
    "test_data = test_data.withColumn('pickup_time', from_unixtime(unix_timestamp(col('pickup_datetime'), 'yyyy-MM-dd HH:mm:ss'), 'HH:mm:ss'))\n",
    "time_split = split(col('pickup_time'), ':')\n",
    "\n",
    "# Calculate the total number of seconds since midnight\n",
    "seconds_from_midnight = (time_split.getItem(0).cast(\"int\") * 3600) + (time_split.getItem(1).cast(\"int\") * 60) + time_split.getItem(2).cast(\"int\")\n",
    "\n",
    "# Add new column to DataFrame\n",
    "test_data = test_data.withColumn('seconds_from_midnight', seconds_from_midnight)\n",
    "\n",
    "# Eigenvectors can now be created using new numeric columns\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=['seconds_from_midnight', 'pickup_longitude', 'pickup_latitude', 'passenger_count'],\n",
    "    outputCol='features'\n",
    ")\n",
    "test_data = assembler.transform(test_data)\n",
    "test_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "651228cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred                    \n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/usr/lib/spark/jars/spark-core_2.12-3.5.0.jar) to field java.nio.charset.Charset.name\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor Latitude Predictions:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+----------------+---------------+-----------------+----------------+---------------+-----------+---------------------+--------------------+------------------+\n",
      "|fare_amount|    pickup_datetime|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|passenger_count|pickup_time|seconds_from_midnight|            features|        prediction|\n",
      "+-----------+-------------------+----------------+---------------+-----------------+----------------+---------------+-----------+---------------------+--------------------+------------------+\n",
      "|       12.9|2011-01-29 01:50:07|             0.0|            0.0|              0.0|             0.0|              1|   01:50:07|                 6607|[6607.0,0.0,0.0,1.0]|0.1648562386645145|\n",
      "|       11.7|2011-07-28 00:08:28|      -73.989378|      40.741525|       -73.955272|       40.776918|              1|   00:08:28|                  508|[508.0,-73.989378...| 40.71143871567419|\n",
      "|       12.1|2010-01-21 04:17:34|      -73.988655|      40.758316|        -74.01221|       40.707129|              1|   04:17:34|                15454|[15454.0,-73.9886...| 40.71155048530598|\n",
      "|        8.5|2013-03-30 08:58:00|       -73.95023|       40.77969|       -73.968578|       40.761727|              1|   08:58:00|                32280|[32280.0,-73.9502...| 40.73185950195206|\n",
      "|        5.0|2014-12-20 19:30:00|      -73.991202|      40.750822|       -73.984685|       40.742962|              1|   19:30:00|                70200|[70200.0,-73.9912...|40.714781384970145|\n",
      "+-----------+-------------------+----------------+---------------+-----------------+----------------+---------------+-----------+---------------------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "RandomForestRegressor Longitude Predictions:\n",
      "+-----------+-------------------+----------------+---------------+-----------------+----------------+---------------+-----------+---------------------+--------------------+-------------------+\n",
      "|fare_amount|    pickup_datetime|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|passenger_count|pickup_time|seconds_from_midnight|            features|         prediction|\n",
      "+-----------+-------------------+----------------+---------------+-----------------+----------------+---------------+-----------+---------------------+--------------------+-------------------+\n",
      "|       12.9|2011-01-29 01:50:07|             0.0|            0.0|              0.0|             0.0|              1|   01:50:07|                 6607|[6607.0,0.0,0.0,1.0]|-2.4689763301169267|\n",
      "|       11.7|2011-07-28 00:08:28|      -73.989378|      40.741525|       -73.955272|       40.776918|              1|   00:08:28|                  508|[508.0,-73.989378...| -73.90748360931869|\n",
      "|       12.1|2010-01-21 04:17:34|      -73.988655|      40.758316|        -74.01221|       40.707129|              1|   04:17:34|                15454|[15454.0,-73.9886...| -73.90748360931869|\n",
      "|        8.5|2013-03-30 08:58:00|       -73.95023|       40.77969|       -73.968578|       40.761727|              1|   08:58:00|                32280|[32280.0,-73.9502...| -73.90838093591188|\n",
      "|        5.0|2014-12-20 19:30:00|      -73.991202|      40.750822|       -73.984685|       40.742962|              1|   19:30:00|                70200|[70200.0,-73.9912...| -73.91080453204842|\n",
      "+-----------+-------------------+----------------+---------------+-----------------+----------------+---------------+-----------+---------------------+--------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load RandomForestRegressor model\n",
    "latfinal_path = \"gs://228bucket/Models/latfinal\"\n",
    "lgfinal_path =\"gs://228bucket/Models/lgfinal\"\n",
    "latfinal = RandomForestRegressionModel.load(latfinal_path)\n",
    "lgfinal = RandomForestRegressionModel.load(lgfinal_path)\n",
    "# Make predictions using RandomForestRegressor\n",
    "latfinal_predictions = latfinal.transform(test_data)\n",
    "lgfinal_predictions = lgfinal.transform(test_data)\n",
    "\n",
    "print(\"RandomForestRegressor Latitude Predictions:\")\n",
    "latfinal_predictions.show(5)\n",
    "print(\"RandomForestRegressor Longitude Predictions:\")\n",
    "lgfinal_predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba94ede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}