{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "984672e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import RandomForestRegressionModel\n",
    "from pyspark.ml.regression import GBTRegressionModel\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, MinMaxScaler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.sql.functions import col, unix_timestamp, dayofweek, hour, month, udf\n",
    "from pyspark.sql.types import FloatType\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "779236b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/16 03:06:59 INFO SparkEnv: Registering MapOutputTracker\n",
      "24/05/16 03:06:59 INFO SparkEnv: Registering BlockManagerMaster\n",
      "24/05/16 03:06:59 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "24/05/16 03:06:59 INFO SparkEnv: Registering OutputCommitCoordinator\n"
     ]
    }
   ],
   "source": [
    "# Create SparkSession\n",
    "spark = SparkSession.builder.appName(\"Demo7\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6625b437",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Schema:\n",
      "root\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- pickup_longitude: double (nullable = true)\n",
      " |-- pickup_latitude: double (nullable = true)\n",
      " |-- dropoff_longitude: double (nullable = true)\n",
      " |-- dropoff_latitude: double (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:====================================================>    (22 + 2) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows in Test Data: 4284701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Load the data from CSV\n",
    "data = spark.read.csv('gs://228bucket/processed_train_2.0.csv/processed_dataset_2.0.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Create test data by sampling from the original data\n",
    "test_data = data.sample(withReplacement=False, fraction=0.10)\n",
    "\n",
    "# Show some information about the test data\n",
    "print(\"Test Data Schema:\")\n",
    "test_data.printSchema()\n",
    "\n",
    "print(\"Number of Rows in Test Data:\", test_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62dd9098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Save test data to CSV to create test demo data\n",
    "test_data.write.csv('gs://228bucket/test_demo_data1.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e8ca4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+----------------+---------------+-----------------+----------------+---------------+\n",
      "|fare_amount|    pickup_datetime|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|passenger_count|\n",
      "+-----------+-------------------+----------------+---------------+-----------------+----------------+---------------+\n",
      "|       12.0|2014-07-10 11:04:00|      -73.995332|      40.739397|       -73.969153|        40.76269|              1|\n",
      "|        7.3|2012-06-02 00:10:29|      -73.988829|      40.749249|        -74.00024|       40.728748|              4|\n",
      "|        4.1|2011-06-21 18:45:00|       -74.00273|      40.749548|       -73.997283|       40.757093|              1|\n",
      "|       14.5|2010-01-31 19:50:59|      -73.949526|      40.772658|       -73.991168|       40.748733|              1|\n",
      "|       12.1|2011-01-22 02:13:00|      -73.963807|      40.710655|       -73.960502|       40.675922|              2|\n",
      "+-----------+-------------------+----------------+---------------+-----------------+----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the data from CSV\n",
    "test_data = spark.read.csv('gs://228bucket/test_demo_data1.csv', header=True, inferSchema=True)\n",
    "test_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b9aec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    " def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "        if lat1 == lat2 and lon1 == lon2:\n",
    "            return 0.0\n",
    "        else:\n",
    "            R = 6371.0  # Radius of the Earth in kilometers\n",
    "            lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])  # Convert degrees to radians\n",
    "            dlat = lat2 - lat1\n",
    "            dlon = lon2 - lon1\n",
    "            a = math.sin(dlat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2) ** 2\n",
    "            c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "            distance = R * c\n",
    "            return float(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2212fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def process_data(test_data):\n",
    "    # Convert datetime and extract features\n",
    "    test_data = test_data.withColumn(\"pickup_datetime\", unix_timestamp(col(\"pickup_datetime\"), \"yyyy-MM-dd'T'HH:mm:ss.SSSX\").cast(\"timestamp\"))\n",
    "    test_data = test_data.withColumn(\"pickup_hour\", hour(col(\"pickup_datetime\")))\n",
    "    test_data = test_data.withColumn(\"day_of_week\", dayofweek(col(\"pickup_datetime\")))\n",
    "    test_data = test_data.withColumn(\"month\", month(col(\"pickup_datetime\")))\n",
    "\n",
    "    udf_calculate_distance = udf(calculate_distance, FloatType())\n",
    "    test_data = test_data.withColumn(\"distance\", udf_calculate_distance(col(\"pickup_latitude\"), col(\"pickup_longitude\"), col(\"dropoff_latitude\"), col(\"dropoff_longitude\")))\n",
    "    \n",
    "    feature_columns = [\"passenger_count\", \"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\", \"distance\", \"pickup_hour\", \"day_of_week\", \"month\"]\n",
    "    \n",
    "    # Assemble the feature columns into a single vector column\n",
    "    assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "    test_data = assembler.transform(test_data)\n",
    "    \n",
    "    # Define the MinMaxScaler\n",
    "    scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "\n",
    "    # Fit the MinMaxScaler to the training data\n",
    "    scaler_model = scaler.fit(test_data)\n",
    "\n",
    "    # Transform the training data\n",
    "    test_data_scaled = scaler_model.transform(test_data)\n",
    "    return test_data_scaled\n",
    "\n",
    "scaled_test_data = process_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ba9fc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a61bb5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor Predictions:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 28:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------+---------------+-----------------+----------------+---------------+-----------+-----------+-----+---------+--------------------+--------------------+------------------+\n",
      "|    pickup_datetime|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|passenger_count|pickup_hour|day_of_week|month| distance|            features|      scaledFeatures|        prediction|\n",
      "+-------------------+----------------+---------------+-----------------+----------------+---------------+-----------+-----------+-----+---------+--------------------+--------------------+------------------+\n",
      "|2014-07-10 11:04:00|      -73.995332|      40.739397|       -73.969153|        40.76269|              1|         11|          5|    7| 3.401677|[1.0,-73.995332,4...|[0.0,0.3171129185...|17.883390490285027|\n",
      "|2012-06-02 00:10:29|      -73.988829|      40.749249|        -74.00024|       40.728748|              4|          0|          7|    6| 2.474042|[4.0,-73.988829,4...|[0.01449275362318...| 17.75730389592079|\n",
      "|2011-06-21 18:45:00|       -74.00273|      40.749548|       -73.997283|       40.757093|              1|         18|          3|    6|0.9562309|[1.0,-74.00273,40...|[0.0,0.3170689291...|18.337080680957335|\n",
      "|2010-01-31 19:50:59|      -73.949526|      40.772658|       -73.991168|       40.748733|              1|         19|          1|    1| 4.402067|[1.0,-73.949526,4...|[0.0,0.3173852868...|18.275295315489835|\n",
      "|2011-01-22 02:13:00|      -73.963807|      40.710655|       -73.960502|       40.675922|              2|          2|          7|    1|3.8721719|[2.0,-73.963807,4...|[0.00483091787439...|18.209013364166452|\n",
      "+-------------------+----------------+---------------+-----------------+----------------+---------------+-----------+-----------+-----+---------+--------------------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Load RandomForestRegressor model\n",
    "rf_model_path = \"gs://228bucket/Models/rf_model\"\n",
    "rf_model = RandomForestRegressionModel.load(rf_model_path)\n",
    "\n",
    "# Make predictions using RandomForestRegressor\n",
    "rf_predictions = rf_model.transform(scaled_test_data)\n",
    "\n",
    "print(\"RandomForestRegressor Predictions:\")\n",
    "rf_predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0a67ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------+---------------+-----------------+----------------+---------------+-----------+-----------+-----+---------+--------------------+--------------------+------------------+\n",
      "|    pickup_datetime|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|passenger_count|pickup_hour|day_of_week|month| distance|            features|      scaledFeatures|        prediction|\n",
      "+-------------------+----------------+---------------+-----------------+----------------+---------------+-----------+-----------+-----+---------+--------------------+--------------------+------------------+\n",
      "|2014-07-10 11:04:00|      -73.995332|      40.739397|       -73.969153|        40.76269|              1|         11|          5|    7| 3.401677|[1.0,-73.995332,4...|[0.0,0.3171129185...|17.883390490285027|\n",
      "|2012-06-02 00:10:29|      -73.988829|      40.749249|        -74.00024|       40.728748|              4|          0|          7|    6| 2.474042|[4.0,-73.988829,4...|[0.01449275362318...| 17.75730389592079|\n",
      "|2011-06-21 18:45:00|       -74.00273|      40.749548|       -73.997283|       40.757093|              1|         18|          3|    6|0.9562309|[1.0,-74.00273,40...|[0.0,0.3170689291...|18.337080680957335|\n",
      "|2010-01-31 19:50:59|      -73.949526|      40.772658|       -73.991168|       40.748733|              1|         19|          1|    1| 4.402067|[1.0,-73.949526,4...|[0.0,0.3173852868...|18.275295315489835|\n",
      "|2011-01-22 02:13:00|      -73.963807|      40.710655|       -73.960502|       40.675922|              2|          2|          7|    1|3.8721719|[2.0,-73.963807,4...|[0.00483091787439...|18.209013364166452|\n",
      "|2011-01-28 09:06:00|      -73.839942|      40.777855|       -73.868618|       40.732975|              1|          9|          6|    1|5.5442314|[1.0,-73.839942,4...|[0.0,0.3180368872...| 19.12647809464538|\n",
      "|2010-07-01 22:23:31|      -73.988693|      40.767599|       -74.000372|       40.740477|              1|         22|          5|    7|3.1722207|[1.0,-73.988693,4...|[0.0,0.3171523949...| 18.70008360406514|\n",
      "|2014-05-31 22:17:03|       -73.98825|      40.745033|       -73.989824|       40.729847|              1|         22|          7|    5|1.6938056|[1.0,-73.98825,40...|[0.0,0.3171550290...| 18.56558986413028|\n",
      "|2012-09-29 11:32:00|      -73.987375|      40.739642|        -74.00706|       40.740812|              1|         11|          7|    9|1.6635516|[1.0,-73.987375,4...|[0.0,0.3171602318...| 18.12543454231894|\n",
      "|2011-04-17 19:08:00|      -73.991502|       40.75523|       -73.972097|       40.786485|              5|         19|          1|    4|3.8404055|[5.0,-73.991502,4...|[0.01932367149758...|18.169052041350156|\n",
      "|2012-02-10 20:32:38|      -73.959194|       40.77366|       -73.966469|       40.764148|              1|         20|          6|    2|1.2223107|[1.0,-73.959194,4...|[0.0,0.3173277997...|18.751213654668536|\n",
      "|2013-09-17 18:08:00|      -73.980478|      40.763682|       -74.006742|       40.720242|              1|         18|          3|    9|5.3129854|[1.0,-73.980478,4...|[0.0,0.3172012423...| 18.67080532009612|\n",
      "|2014-10-03 19:38:00|      -73.975137|      40.757552|       -73.968475|       40.767992|              5|         19|          6|   10|1.2893578|[5.0,-73.975137,4...|[0.01932367149758...|18.275874275514635|\n",
      "|2012-08-10 19:57:00|      -73.979102|      40.782072|        -73.96045|        40.79754|              1|         19|          6|    8|2.3289425|[1.0,-73.979102,4...|[0.0,0.3172094242...|18.091647973664553|\n",
      "|2013-05-09 14:21:18|      -73.978172|      40.756574|       -73.975077|       40.765343|              1|         14|          5|    5|1.0093106|[1.0,-73.978172,4...|[0.0,0.3172149541...|17.929958832839816|\n",
      "|2011-05-29 22:14:00|       -73.95662|      40.771117|       -73.961452|       40.759992|              5|         22|          1|    5|1.3022584|[5.0,-73.95662,40...|[0.01932367149758...|18.428504866645138|\n",
      "|2011-12-01 20:09:00|             0.0|            0.0|              0.0|             0.0|              5|         20|          5|   12|      0.0|(9,[0,6,7,8],[5.0...|[0.01932367149758...|12.143925930862501|\n",
      "|2011-10-29 18:56:59|      -73.961639|      40.779469|       -73.958863|       40.760809|              4|         18|          7|   10| 2.088025|[4.0,-73.961639,4...|[0.01449275362318...|17.905061177866187|\n",
      "|2014-04-08 09:18:00|      -73.945642|      40.778062|       -73.959675|       40.760422|              1|          9|          3|    4|2.2899687|[1.0,-73.945642,4...|[0.0,0.3174083816...| 17.71941640730101|\n",
      "|2011-03-12 09:55:31|      -73.976834|      40.743775|       -73.966576|       40.752981|              1|          9|          7|    3|1.3396262|[1.0,-73.976834,4...|[0.0,0.3172229100...|17.872333284961176|\n",
      "+-------------------+----------------+---------------+-----------------+----------------+---------------+-----------+-----------+-----+---------+--------------------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 38:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rf_predictions.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9919564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GBT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c95854ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBTRegressor Predictions:\n",
      "+-------------------+----------------+---------------+-----------------+----------------+---------------+-----------+-----------+-----+---------+--------------------+--------------------+------------------+\n",
      "|    pickup_datetime|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|passenger_count|pickup_hour|day_of_week|month| distance|            features|      scaledFeatures|        prediction|\n",
      "+-------------------+----------------+---------------+-----------------+----------------+---------------+-----------+-----------+-----+---------+--------------------+--------------------+------------------+\n",
      "|2014-07-10 11:04:00|      -73.995332|      40.739397|       -73.969153|        40.76269|              1|         11|          5|    7| 3.401677|[1.0,-73.995332,4...|[0.0,0.3171129185...|  36.9656465475079|\n",
      "|2012-06-02 00:10:29|      -73.988829|      40.749249|        -74.00024|       40.728748|              4|          0|          7|    6| 2.474042|[4.0,-73.988829,4...|[0.01449275362318...|32.592879152855325|\n",
      "|2011-06-21 18:45:00|       -74.00273|      40.749548|       -73.997283|       40.757093|              1|         18|          3|    6|0.9562309|[1.0,-74.00273,40...|[0.0,0.3170689291...| 35.87778918146441|\n",
      "|2010-01-31 19:50:59|      -73.949526|      40.772658|       -73.991168|       40.748733|              1|         19|          1|    1| 4.402067|[1.0,-73.949526,4...|[0.0,0.3173852868...| 49.10163317602768|\n",
      "|2011-01-22 02:13:00|      -73.963807|      40.710655|       -73.960502|       40.675922|              2|          2|          7|    1|3.8721719|[2.0,-73.963807,4...|[0.00483091787439...| 40.31815640258355|\n",
      "+-------------------+----------------+---------------+-----------------+----------------+---------------+-----------+-----------+-----+---------+--------------------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 37:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Load GBTRegressor model\n",
    "gbt_model_path = \"gs://228bucket/Models/gbt_model\"\n",
    "gbt_model = GBTRegressionModel.load(gbt_model_path)\n",
    "\n",
    "# Make predictions using GBTRegressor\n",
    "gbt_predictions = gbt_model.transform(scaled_test_data)\n",
    "\n",
    "# Show predictions\n",
    "print(\"GBTRegressor Predictions:\")\n",
    "gbt_predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9536dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}